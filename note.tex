Following the equation in (model-based), we compute the state transition probabilty by:
and reward function by:
We begin by separate the state variable into the variables which may change after the executaion of
actions, and those stay the same.
Given the current state $s$, the variables which may change are denoted by $\Phi(s)$.
The rest are denoted by $\bar{\Phi(s)}.$ 
The state transition probality and reward function now can be rewrite as:


If P(s, s', a| C(s)) = P(s, s', a| C(s1)),  
then it is a safe state abstraction.


1. model-based should focus on 


