%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Introduction}
\label{ch:intro}

\section{Problem Statement}
The objective of this project is to build a software which can play a wide range 
of video games. To achieve this goal, the software shall not possess any game-specific 
information. Besides, the software shall be able to play the games in a non-intrusive approach.
That is, the software shall be able to extract the necessary information 
from the screenshot of the games and control the games from standard input devices such as keyboard.
Since most of video games use graphical display as the primary interface, this requirement allows
the software to be applied to different video games.

\section{Why video games?}
Over the past decade, substantial research has been conducted to teach computer play classic strategy games such
as Deep Thought\cite{DeepBlue}, TD-Gammon\cite{Gammon}, and GO\cite{Go}.
On the other hand, little research has been made\cite{FPS}\cite{Mario} to extend the effort to other genres of video games.
The genres of video games include not only classic strategy games, but also action, first-person shooter, role-player, adventure, simulation, etc.
Video games introduce a new challenge to the AI community.

The challenge includes:
\begin{itemize}{}

\item A generic algorithm which can adapt to different types of games:
Following the paradigm of \cite{GGP} and \cite{Yavar}, the objective is not to design a good AI for
a specific game. Instead, the objective is to design a good and generic AI to play different games successfully.

\item Large but highly structured states:
For a 256 color video game with resolution $640 \times 480$, it has $256^{640 \times 480}$ states.
The number of states is too big to be tractable. However, a video game often consists of small number of objects.
If we can figure out a way to represent the relationship of these objects, the number of states
can be reduced.

\item Dynamic number of agents:
Unlike classic strategy games, the number of agents in video games is highly dynamic.
The number of agents may increase over time and decrease if killed.
It is a challenge which doesn't exist in classic strategy games.
\end{itemize}

Video games can be viewed as a abstract representation of the real world. Often can we find the 
correspondence between such an artificial world to a real-world problem\cite{KeepAway}.
Focusing on Video games allows us to attack a real-world problem without tackling unnecessary details, while maintaining sufficient 
level of abstraction. In addition, video games are well-understood and customizable environments. 
It allows us to test an AI algorithm and justify if the result is correct\cite{Yavar}.

Another possible application is the AI of video games.
Nowadays, the AI engineers usually need to craft the behavior of AI by hand. 
The process are time-consuming and the hard-coded behavior would produce unrealistic AI behavior.
If we can design a generic agent and let it act reactively with the environment, it can produce 
more various and unpredictable behaviors.

\section{Why apply computer vision to video games?}

The reason behind is the reality that most of the video games do not have source codes which are publicly available.
If a researcher needs to test his algorithm on Super Mario Bros., all he can do is to apply it on Infinite Mario Bros.,
which is an open source clone of original Super Mario Bros. He cannot test his algorithm on Mario Bros. 1 or 2, which are available
on binary format. If a researcher does not have source codes, he cannot extract the game states like the location
of Koopa Troopas which are mandatory for any AI algorithm to work. 

Using computer vision techniques to extract the information from the game screen is a way to solve this problem.
Because most of the video games uses graphics as the primary interface to interact with the player, it contains
the necessary information for the player to play. The use of computer vision allows us to test the algorithm
non-intrusively, without the effort to hack the game engine or reimplement the game.

Besides, the vision allows a more generic way for a computer to play a video game. It creates 
new applications which cannot be done by intrusive approaches.

\begin{itemize}{}
\item Non-intrusive and generic AI:
Have you ever played a good game with poor AI? Can you change it with a better one?
Without the source codes of the game or the engine support, the answer is usually "No".
Nevertheless, if we could design a software which can learn to play any video game, 
the answer can be changed to "Yes". The non-intrusive and generic agents can be 
applied to any video games with/without the support from the game company.

\item Modding: 
Game modding becomes popular in recent years \cite{Modding}. 
Modding allows users to customize the video games to suite their personal tastes.
The modding usually includes the introduce new content, modification of original one, or remove the unsatisfactory elements.
The process can be done by the support of game development kit released by the game company.
It can also be done without the support from the game company. However, the modders need to hack the game engine,
decode the data format and implement their own development kit. 
The process can be time-consuming and tedious.
If we could automate the process by having a software which can 
traverse the game and extract the in-game elements for us, it could save a lot of time.

\end{itemize}

%\chapter{Related Work}
%\label{ch:Related}
\section{Related Work}

There are several works which address how to design a good AI for certain type of video games.
McPartland et al. proposed a approach to allow bots in First-Person Shooter (FPS)
games to learn how to navigate the maze and handle combat \cite{FPS}. M. Smith et al. proposed a coordination 
framework to allow the bots to adapt to different strategy by reinforcement learning \cite{FPS_TEAM}. 
Michael et al. applied a Monte Carlo planning approach for Real-Time Strategy (RTS) gmaes to 
the Rush-the-Flag game \cite{RTS}. Ponsen et al. proposed hierarchical relational learning to learn how to play
the Battle of Survival game \cite{HRRL}. For arcade-style games, \cite{Mario} uses a RL agent to learn
how to play Infinite Mario Bro. Driessens et al. proposed a relational RL to learn how to play the Digger
game. In \cite{OO}, a object-oriented representation is proposed to play pitfall.

Previous works rely on the intrusive approach to provide the states of games for the agents to play.
The agents need to know the information such as the number of objects, the types of objects,
or the health level of players to play the games. The intrusive approach makes it difficult to generalize
to a large number of video games. And the game-specific representation prevents these approaches
to be applied to arbitrary video games.

With the objective to play general video games, our work is most related to 
General Game Playing\cite{GGP} (GGP) and Playing Atari 2600 \cite{Yavar}. 
The objective of GGP is to develop a software agent which can play unspecific games if the rules
are given. Our work follows the same objective. However, due to the complexity of video games, 
it is not clear that how to precisely describe the rules of video games.

Y. Naddaf\cite{Yavar} proposed A.L.E. (Atari 2600 Learning Environment) as the platform to test AI algorithms.
A.L.E. supports fast emulation and generic interface. Fast emulation allows the emulator to run 
games without rendering or sound generation. It can increase the speed in the learning phase.
The generic interface provides AI agents the screenshot and scores in games. It allows us
to build the agents in a game independent way.

Our work is built on A.L.E. However, our work differs from \cite{Yavar} in the following perspective:

\begin{itemize}{}
\item Our work features object-based representation. We argue that objects are the fundamental elements
in video games. The representation allows the agent to develop appropriate policy against specific 
objects. And it also enables the possibility to reuse the knowledge in different stages.
\end{itemize}

