@String{lncs = {Lecture Notes in Computer Science}}
@String{procecoop = {Proceedings of the European Conference on Object-Oriented Programming ({ECOOP})}}

@article{Pasula07,
  title={Learning symbolic models of stochastic domains},
  author={Pasula, H.M. and Zettlemoyer, L.S. and Kaelbling, L.P.},
  journal={Journal of Artificial Intelligence Research},
  volume={29},
  number={1},
  pages={309--352},
  year={2007},
  publisher={AI Access Foundation}
}

@article{Orange04,
  title={Orange: From experimental machine learning to interactive data mining},
  author={Dem{\v{s}}ar, J. and Zupan, B. and Leban, G. and Curk, T.},
  journal={Knowledge discovery in databases: PKDD 2004},
  pages={537--539},
  year={2004},
  publisher={Springer}
}

@book{Bellman57,
  title={Dynamic programming},
  author={Bellman, RE},
  year={1957},
  publisher={Princeton University Press, Princeton, NJ}
}


@article{Nason05,
  title={Soar-RL: Integrating reinforcement learning with Soar},
  author={Nason, S. and Laird, J.E.},
  journal={Cognitive Systems Research},
  volume={6},
  number={1},
  pages={51--59},
  year={2005},
  publisher={Elsevier}
}

@techreport{Rummery94,
    author = {G. Rummery and M. Niranjan},
    title = {On-line {Q}-learning using connectionist systems},
    number = {CUED/FINFENG/TR 166},
    year = {1994},
    institution = {Cambridge University Engineering Department},
}

@phdthesis{Watkins89,
  title={Learning from delayed rewards},
  author={Christopher Watkins},
  year={1989},
  url = {http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf},
  school={King's College, Cambridge},
}

@techreport{Mohan09,
    author = {Mohan, S. and Laird, J. E.},
    title = {Learning to play {Mario}},
    number = {CCA-TR-2009-03},
    year = {2009},
    institution = {Center for Cognitive Architecture, University of Michigan},
}


@misc{Gibson09,
  author = {Richard Gibson and Nick Abou Risk},
  title = {Mario, State Abstractions and the Wonderful World of Options},
  howpublished = "\url{https://sites.google.com/site/richardggibson/publications-and-presentations}",
  year={2009}
}


@misc{Paul09,
  author = {SaeHoon Yi and Paul Ringstad and Fengming Wang},
  title = {An Approach to Infinite {Mario}},
  howpublished = "\url{http://2009.rl-competition.org/results/ringstad-mario.pdf}",
  year={2009}
}


@INPROCEEDINGS{Mohan10,
AUTHOR = "Shiwali Mohan and John E. Laird",
TITLE = "Relational Reinforcement Learning in {I}nfinite {M}ario.",
booktitle = "AAAI'10",
YEAR = {2010}}

@inproceedings{Robin09,
  title={The 2009 {M}ario {AI} Competition},
  author={Togelius, J. and Karakovskiy, S. and Baumgarten, R.},
  booktitle={Evolutionary Computation (CEC), 2010 IEEE Congress on},
  pages={1--8},
  year={2010},
  organization={IEEE}
}

@inproceedings{Wingate09,
 author = {Wingate, David and Diuk, Carlos and Li, Lihong and Taylor, Matthew and Frank, Jordan},
 title = {Workshop summary: Results of the 2009 reinforcement learning competition},
 booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
 series = {ICML '09},
 year = {2009},
 location = {Montreal, Quebec, Canada},
 pages = {6:1--6:1},
 articleno = {6},
 numpages = {1},
 url = {http://doi.acm.org/10.1145/1553374.1553544},
 doi = {http://doi.acm.org/10.1145/1553374.1553544},
 acmid = {1553544},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@INPROCEEDINGS{HowWhat09,
author={Togelius, J. and Karakovskiy, S. and Koutnik, J. and Schmidhuber, J.},
booktitle={Computational Intelligence and Games, 2009. CIG 2009. IEEE Symposium on}, title={Super mario evolution},
year={2009},
month={sept.},
volume={},
number={},
pages={156--161},
doi={10.1109/CIG.2009.5286481},
ISSN={},}

@inproceedings{Ross11,
 author = {Stephane Ross and Geoffrey Gordon and Drew Bagnell},
 title = {Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning},
 booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
 series = {AAAI'92},
 year = {2011},
} 
@inproceedings{Singh92,
 author = {Singh, Satinder P.},
 title = {Reinforcement learning with a hierarchy of abstract models},
 booktitle = {Proceedings of the Tenth National Conference on Artificial Intelligence},
 series = {AAAI'92},
 year = {1992},
 location = {San Jose, California},
 pages = {202--207},
 numpages = {6},
 publisher = {AAAI Press},
} 

@inproceedings{Dayan95,
 author = {Dayan, Peter and Hinton, Geoffrey E.},
 title = {Feudal Reinforcement Learning},
 booktitle = {Advances in Neural Information Processing Systems 5},
 year = {1993},
 pages = {271--278},
 numpages = {8},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 




@inproceedings{Walsh09,
 author = {Walsh, Thomas J. and Szita, Istv\'{a}n and Diuk, Carlos and Littman, Michael L.},
 title = {Exploring compact reinforcement-learning representations with linear regression},
 booktitle = {Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence},
 series = {UAI '09},
 year = {2009},
 location = {Montreal, Quebec, Canada},
 pages = {591--598},
 numpages = {8},
 publisher = {AUAI Press},
 address = {Arlington, Virginia, United States},
} 

@book{Howard1960,
  title={Dynamic programming and {Markov} processes},
  author={Howard, R.A.},
  year={1960},
  publisher={The MIT Press}
}

@book{Puterman94,
  title={{Markov} decision processes: discrete stochastic dynamic programming},
  author={Puterman, M.L.},
  year={1994},
  publisher={John Wiley \& Sons, Inc.}
}

@book{Neurodynamic,
  title={Neuro-dynamic programming},
  author={Bertsekas, D.P. and Tsitsiklis, J.N.},
  year={1996},
  publisher={Athena Scientific}
}

@article{HRLSurvey,
   author = {Barto, Andrew G. and Mahadevan, Sridhar},
   title = {Recent Advances in Hierarchical Reinforcement Learning},
   journal = {Discrete Event Dynamic Systems},
   publisher = {Springer Netherlands},
   keyword = {Engineering},
   pages = {341-379},
   volume = {13},
   issue = {4},
   year = {2003}
}

@inproceedings{Wynkoop08,
 author = {Wynkoop, Michael and Dietterich, Thomas},
 title = {Learning MDP Action Models Via Discrete Mixture Trees},
 booktitle = {Proceedings of the European conference on Machine Learning and Knowledge Discovery in Databases - Part II},
 series = {ECML PKDD '08},
 year = {2008},
 location = {Antwerp, Belgium},
 pages = {597--612},
 numpages = {16},
 url = {http://dx.doi.org/10.1007/978-3-540-87481-2_39},
 doi = {http://dx.doi.org/10.1007/978-3-540-87481-2_39},
 acmid = {1432039},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}
@article{Boutilier99,
 author = {Boutilier, Craig and Dearden, Richard and Goldszmidt, Mois\'{e}s},
 title = {Stochastic dynamic programming with factored representations},
 journal = {Artificial Intelligence},
 volume = {121},
 issue = {1-2},
 month = {August},
 year = {2000},
 issn = {0004-3702},
 pages = {49--107},
 numpages = {59},
 url = {http://dl.acm.org/citation.cfm?id=352769.352780},
 doi = {10.1016/S0004-3702(00)00033-3},
 acmid = {352780},
 publisher = {Elsevier Science Publishers Ltd.},
 address = {Essex, UK},
} 


@INPROCEEDINGS{envelope-planning,
    author = {Natalia H. Gardiol and Leslie Pack Kaelbling},
    title = {Envelope-based Planning in Relational MDPs},
    booktitle = {Proceedings NIPS-2003},
    year = {2003},
    publisher = {MIT Press}
}


@INPROCEEDINGS{Pasula04,
    author = {Hanna M. Pasula and Luke S. Zettlemoyer and Leslie Pack Kaelbling},
    title = {Learning probabilistic relational planning rules},
    booktitle = {PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON AUTOMATED PLANNING AND SCHEDULING},
    year = {2004},
    publisher = {}
}

@ARTICLE{SMDP,
    author = {Richard Sutton and Doina Precup and Satinder Singh},
    title = {Between {MDP}s and {S}emi-{MDP}s: A Framework for Temporal Abstraction in Reinforcement Learning},
    journal = {Artificial Intelligence},
    year = {1999},
    volume = {112},
    issue = {1-2},
    month = {August},
    issn = {0004-3702},
    pages = {181--211},
    numpages = {31},
    publisher = {Elsevier Science Publishers Ltd.},
    address = {Essex, UK},
}

@INPROCEEDINGS{HAMQ,
    author = {Ronald Parr and Stuart Russell},
    title = {Reinforcement Learning with Hierarchies of Machines},
    booktitle = {Advances in Neural Information Processing Systems 10},
    year = {1997},
    pages = {1043--1049},
    publisher = {MIT Press}
}

@inproceedings{Diuk,
    author = {Diuk, Carlos and Strehl, Alexander L. and Littman, Michael L.},
    title = {A hierarchical approach to efficient reinforcement learning in deterministic domains},
    booktitle = {Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems},
    series = {AAMAS '06},
    year = {2006},
    location = {Hakodate, Japan},
    pages = {313--319},
    numpages = {7},
    url = {http://doi.acm.org/10.1145/1160633.1160686},
    doi = {http://doi.acm.org/10.1145/1160633.1160686},
    acmid = {1160686},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {factored representations, hierarchical reinforcement learning, reinforcement learning, sample complexity},
} 

@inproceedings{HLearning,
    author = {Seri, Sandeep and Tadepalli, Prasad},
    title = {Model-based Hierarchical Average-reward Reinforcement Learning},
    booktitle = {Proceedings of the Nineteenth International Conference on Machine Learning},
    series = {ICML '02},
    year = {2002},
    pages = {562--569},
    numpages = {8},
    url = {http://portal.acm.org/citation.cfm?id=645531.656009},
    acmid = {656009},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA},
} 


@INPROCEEDINGS{Dyna,
    author = {Richard S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {Proceedings of the Seventh International Conference on Machine Learning},
    year = {1990},
    pages = {216--224},
    publisher = {Morgan Kaufmann}
}


@INPROCEEDINGS{ApproxDyna,
    author = {Richard S. Sutton and Csaba Szepesvári and Alborz Geramifard and Michael Bowling},
    title = {Dyna-style planning with linear function approximation and prioritized sweeping},
    booktitle = {Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence},
    year = {2008}
}

@INPROCEEDINGS{ApproxTree,
    author = {Thomas Degris and Olivier Sigaud},
    title = {Learning the structure of factored {Markov} decision processes in reinforcement learning problems},
    booktitle = {Proceedings of the 23rd international conference on Machine learning},
    year = {2006},
    pages = {257--264}
}
@INPROCEEDINGS{ApproxFactor,
    author = {Carlos Guestrin and Relu Patrascu and Dale Schuurmans},
    title = {Algorithm-Directed Exploration for Model-Based Reinforcement Learning in Factored {MDP}s},
    booktitle = {Proceedings of the International Conference on Machine Learning},
    year = {2002},
    pages = {235--242},
    publisher = {Morgan Kaufmann Publishers Inc}
}

@INPROCEEDINGS{HexQ,
    author = {Bernhard Hengst},
    title = {Discovering Hierarchy in Reinforcement Learning with {HEXQ}},
    booktitle = {Proceedings of the Nineteenth International Conference on Machine Learning},
    year = {2002},
    pages = {243--250},
    publisher = {Morgan Kaufmann}
}

@InProceedings{Hester09,
  author={Todd Hester and Peter Stone},
  title={An Empirical Comparison of Abstraction in Models of {Markov} Decision Processes},
  booktitle = {Proceedings of the ICML/UAI/COLT Workshop on Abstraction in Reinforcement Learning},
  location = {Montreal, Canada},
  month = {June},
  year = {2009}
}

@INPROCEEDINGS{LSTD99,
    author = {Justin A. Boyan},
    title = {Least-Squares Temporal Difference Learning},
    booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning},
    year = {1999},
    pages = {49--56},
    publisher = {Morgan Kaufmann}
}


@INPROCEEDINGS{SPUDD,
    author = {Jesse Hoey and Robert St-Aubin and Alan Hu and Craig Boutilier},
    title = {{SPUDD}: Stochastic planning using decision diagrams},
    booktitle = {Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence},
    year = {1999},
    pages = {279--288},
    publisher = {Morgan Kaufmann}
}

@INPROCEEDINGS{Andre02,
    author = {David Andre and Stuart J. Russell},
    title = {State Abstraction for Programmable Reinforcement Learning Agents},
    booktitle = {Proceedings of the Eighteenth National Conference on Artificial Intelligence},
    year = {2002},
    pages = {119--125},
    publisher = {AAAI Press}
}

@phdthesis{HORDQ,
    author = {David Andre},
    title = {Programmable Reinforcement Learning Agents},
    year = {2003},
    url = {http://www.davidandre.com/diss.html},
    school = {University of California at Berkeley},
}
@mastersthesis{Vlad,
    author = {Vlad M. Cora },
    title = {Model-Based Active Learning in Hierarchical Policies},
    year = {2008},
    url = {https://circle.ubc.ca/handle/2429/737},
    school = {University of British Columbia},
}


@INPROCEEDINGS{HybridPolicy,
    author = {Mohammad Ghavamzadeh and Sridhar Mahadevan},
    title = {Hierarchical policy gradient algorithms},
    booktitle = {Proceedings of the Twentieth International Conference on Machine Learning},
    year = {2003},
    pages = {226--233},
    publisher = {AAAI Press}
}

@inproceedings{RMaxQ,
    author = {Jong, Nicholas K. and Stone, Peter},
    title="Hierarchical Model-Based Reinforcement Learning: {Rmax} + {MAXQ}",
    booktitle="Proceedings of the Twenty-Fifth International Conference on Machine Learning",
    year = {2008},
    location = {Helsinki, Finland},
    pages = {432--439},
    numpages = {8},
    publisher = {ACM},
    address = {New York, NY, USA},
} 


@ARTICLE{MaxQJ,
    author = {Thomas G. Dietterich},
    title = {Hierarchical Reinforcement Learning with the {MAXQ} Value Function Decomposition},
    journal = {Journal of Artificial Intelligence Research},
    year = {2000},
    volume = {13},
    pages = {227--303}
}

@incollection{MaxQNoUse,
    author = {Dietterich, Thomas},
    affiliation = {Oregon State University Corvallis Oregon USA},
    title = {An Overview of {MAXQ} Hierarchical Reinforcement Learning},
    booktitle = {Abstraction, Reformulation, and Approximation},
    series = {Lecture Notes in Computer Science},
    editor = {Choueiry, Berthe and Walsh, Toby},
    publisher = {Springer Berlin / Heidelberg},
    pages = {26-44},
    volume = {1864},
    year = {2000}
}


@INPROCEEDINGS{ComplexityMDP,
    author = {Michael L. Littman and Thomas L. Dean and Leslie Pack Kaelbling},
    title = {On the complexity of solving {Markov} decision problems},
    booktitle = {IN PROC. OF THE ELEVENTH INTERNATIONAL CONFERENCE ON UNCERTAINTY IN ARTIFICIAL INTELLIGENCE},
    year = {1995},
    pages = {394--402},
    publisher = {}
}

@INPROCEEDINGS{OnlineL1,
    author = {Peter Carbonetto and Mark Schmidt and Nando De Freitas},
    title = {An interior-point stochastic approximation method and an L1-regularized delta rule},
    booktitle = {In Advances in},
    year = {2009},
    publisher = {MIT Press}
}

@article{Planner,
    author = {Matt Zucker and J. Andrew Bagnell},
    title = {Reinforcement Planning: RL for Optimal Planners},
    journal = {CMU-RI-TR-10-14},
    year = {2010},
    publisher = {Carnegie Mellon University},
}
@article{LSPI,
    author = {Lagoudakis, Michail G. and Parr, Ronald},
    title = {Least-squares policy iteration},
    journal = {J. Mach. Learn. Res.},
    volume = {4},
    year = {2003},
    issn = {1532-4435},
    pages = {1107--1149},
    publisher = {JMLR.org},
}
@inproceedings{TDFA09,
    author = {Sutton, Richard S. and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv\'{a}ri, Csaba and Wiewiora, Eric},
    title = {Fast gradient-descent methods for temporal-difference learning with linear function approximation},
    booktitle = {ICML '09: Proceedings of the 26th Annual International Conference on Machine Learning},
    year = {2009},
    pages = {993--1000},
    location = {Montreal, Quebec, Canada},
    doi = {http://doi.acm.org/10.1145/1553374.1553501},
    publisher = {ACM},
    address = {New York, NY, USA},
}

@INPROCEEDINGS{SampleRL,
    author = {Trevor Walker and Jude Shavlik and Richard Maclin},
    title = {Relational reinforcement learning via sampling the space of first-order conjunctive features},
    booktitle = {Proceedings of the ICML Workshop on Relational Reinforcement Learning},
    year = {2004}
}

@INPROCEEDINGS{ALP,
    author = {Scott Sanner},
    title = {Approximate linear programming for first-order MDPs},
    booktitle = {Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence},
    year = {2005},
    pages = {509--517}
}

@article{OldLSTD,
    author = {Bradtke, Steven J. and Barto, Andrew G.},
    title = {Linear Least-Squares algorithms for temporal difference learning},
    journal = {Machine Learning},
    publisher = {Springer Netherlands},
    issn = {0885-6125},
    keyword = {Computer Science},
    pages = {33-57},
    volume = {22},
    issue = {1},
    url = {http://dx.doi.org/10.1007/BF00114723},
    note = {10.1007/BF00114723},
    year = {1996}
}

@article{LSTD,
    author = {Boyan, Justin A.},
    title = {Technical Update: Least-Squares Temporal Difference Learning},
    journal = {Machine Learning},
    publisher = {Springer Netherlands},
    issn = {0885-6125},
    keyword = {Computer Science},
    pages = {233-246},
    volume = {49},
    issue = {2},
    url = {http://dx.doi.org/10.1023/A:1017936530646},
    note = {10.1023/A:1017936530646},
    year = {2002}
}

@inproceedings{L1LSTD,
    author = {Kolter, J. Zico and Ng, Andrew Y.},
    title = {Regularization and feature selection in least-squares temporal difference learning},
    booktitle = {ICML '09: Proceedings of the 26th Annual International Conference on Machine Learning},
    year = {2009},
    pages = {521--528},
    location = {Montreal, Quebec, Canada},
    doi = {http://doi.acm.org/10.1145/1553374.1553442},
    publisher = {ACM},
    address = {New York, NY, USA},
}

@INPROCEEDINGS{LassoTD,
    author={Loth, M. and Davy, M. and Preux, P.},
    journal={Approximate Dynamic Programming and Reinforcement Learning, 2007. ADPRL 2007. IEEE International Symposium on}, title={Sparse Temporal Difference Learning Using LASSO},
    year={2007},
    month={apr.},
    volume={},
    number={},
    pages={352 -359},
    keywords={LASSO;equi-gradient descent algorithm;nonparametric function approximators;online value function estimation;reinforcement learning;sparse temporal difference learning;temporal difference algorithms;function approximation;learning (artificial intelligence);},
    doi={10.1109/ADPRL.2007.368210},
    ISSN={},}

    @INPROCEEDINGS{GraphKernel,
        author = {Thomas G\"{a}rtner and Kurt Driessens and Jan Ramon},
        title = {Graph Kernels and Gaussian Processes for Relational Reinforcement Learning},
        booktitle = {Machine Learning},
        year = {2003},
        pages = {146--163},
        publisher = {Springer}
    }

@INPROCEEDINGS{RessellDecompose,
    author = {Stuart Russell and Andrew L. Zimdars},
    title = {Q-Decomposition for Reinforcement Learning Agents},
    booktitle = {ICML '03: Proceedings of the 20th international conference on Machine learning},
    year = {2003},
    publisher = {ACM},
}
@INPROCEEDINGS{SDP,
    author = {Craig Boutilier},
    title = {Symbolic Dynamic Programming for First-order MDPs},
    booktitle = {In IJCAI},
    year = {2001},
    pages = {690--700},
    publisher = {Morgan Kaufmann}
}

@INPROCEEDINGS{TadSurveyRRL,
    author = {Prasad Tadepalli and Robert Givan and Kurt Driessens},
    title = {Relational reinforcement learning: An overview},
    booktitle = {Proceedings of the ICML’04 Workshop on Relational Reinforcement Learning},
    year = {2004}
}

@TECHREPORT{OtterSurveyRRL,
    author = {Martijn Van Otterlo},
    title = {A Survey of Reinforcement Learning in Relational Domains},
    institution = {CTIT Technical Report Series},
    year = {2005}
}

@INPROCEEDINGS{KNN_RRL,
    author = {Kurt Driessens and Jan Ramon},
    title = {Relational instance based regression for relational reinforcement learning},
    booktitle = {Proceedings of the 20th International Conference on Machine Learning},
    year = {2003},
    pages = {123--130},
    publisher = {AAAI Press}
}

@INPROCEEDINGS{TG,
    author = {Kurt Driessens and Jan Ramon and Hendrik Blockeel},
    title = {Speeding up Relational Reinforcement Learning Through the Use of an Incremental First Order Decision Tree Learner},
    booktitle = {Proceedings of the 13th European Conference on Machine Learning},
    year = {2001},
    pages = {97--108},
    publisher = {Springer-Verlag}
}

@article{Dzeroski01,
    author = {Džeroski, Sašo and De Raedt, Luc and Driessens, Kurt},
    title = {Relational Reinforcement Learning},
    journal = {Machine Learning},
    publisher = {Springer Netherlands},
    issn = {0885-6125},
    keyword = {Computer Science},
    pages = {7-52},
    volume = {43},
    issue = {1},
    year = {2001}
}
@INPROCEEDINGS{Dzeroski98,
    author = {Saso Dzeroski and Luc De Raedt and Hendrik Blockeel},
    title = {Relational Reinforcement Learning},
    booktitle = {Machine Learning},
    year = {1998},
    pages = {7--52},
    publisher = {Morgan Kaufmann}
}

@book{SuttonIntro,
    author = {Sutton, Richard S. and Barto, Andrew G.},
    day = {01},
    howpublished = {Hardcover},
    month = {March},
    publisher = {The MIT Press},
    title = {Reinforcement Learning: An Introduction},
    year = {1998}
}
@book{KevinIntro,
    author = {Shoham, Yoav and Leyton-Brown, Kevin},
    day = {15},
    howpublished = {Hardcover},
    keywords = {learning, multiagent, systems},
    month = {December},
    posted-at = {2010-03-17 13:05:40},
    priority = {5},
    publisher = {Cambridge University Press},
    title = {Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations},
    year = {2008}
}



@inproceedings{RRLTD,
    author = {Asgharbeygi, Nima and Stracuzzi, David and Langley, Pat},
    title = {Relational temporal difference learning},
    booktitle = {ICML '06: Proceedings of the 23rd international conference on Machine learning},
    year = {2006},
    pages = {49--56},
    location = {Pittsburgh, Pennsylvania},
    doi = {http://doi.acm.org/10.1145/1143844.1143851},
    publisher = {ACM},
    address = {New York, NY, USA},
}

@article{RelationalTemplate,
    author = {Proper, Scott and Tadepalli, Prasad},
    title = {Transfer Learning via Relational Templates },
    journal = {Inductive Logic Programming},
    volume = {2010},
    number = {5989},
    year = {2010},
    issn = {0302-9743},
    pages = {186--193},
    publisher = {Springer},
    address = {Berlin, Heidelberg}
}
@inproceedings{RelationalMDP,
    author = {Guestrin, Carlos and Koller, Daphne and Gearhart, Chris and Kanodia, Neal},
    title = {Generalizing plans to new environments in relational MDPs},
    booktitle = {IJCAI'03: Proceedings of the 18th international joint conference on Artificial intelligence},
    year = {2003},
    pages = {1003--1010},
    location = {Acapulco, Mexico},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA},
}

@inproceedings{FPS_TEAM,
    author = {Smith, Megan and Lee-Urban, Stephen and Mu, noz-Avila, Hector},
    title = {RETALIATE: learning winning policies in first-person shooter games},
    booktitle = {IAAI'07: Proceedings of the 19th national conference on Innovative applications of artificial intelligence},
    year = {2007},
    pages = {1801--1806},
    location = {Vancouver, British Columbia, Canada},
    publisher = {AAAI Press},
}

@INPROCEEDINGS{RTS,
    author = {Michael Chung, Michael Buro, Jonathan Schaeffer},
    title = {Monte Carlo planning in RTS games},
    booktitle = {Proceedings of the IEEE Symposium on Computational Intelligence and Games},
    year = {2005},
}

@inproceedings{HRRL,
    author = {Torrey, Lisa and Shavlik, Jude and Walker, Trevor and Maclin, Richard},
    title = {Relational macros for transfer in reinforcement learning},
    booktitle = {ILP'07: Proceedings of the 17th international conference on Inductive logic programming},
    year = {2008},
    pages = {254--268},
    location = {Corvallis, OR, USA},
    publisher = {Springer-Verlag},
    address = {Berlin, Heidelberg},
}

@inproceedings{OO,
    author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
    title = {An object-oriented representation for efficient reinforcement learning},
    booktitle = {ICML '08: Proceedings of the 25th international conference on Machine learning},
    year = {2008},
    pages = {240--247},
    location = {Helsinki, Finland},
    doi = {http://doi.acm.org/10.1145/1390156.1390187},
    publisher = {ACM},
    address = {New York, NY, USA},
}

@inproceedings{GGP,
    author = {Schiffel, Stephan and Thielscher, Michael},
    title = {Fluxplayer: a successful general game player},
    booktitle = {AAAI'07: Proceedings of the 22nd national conference on Artificial intelligence},
    year = {2007},
    pages = {1191--1196},
    location = {Vancouver, British Columbia, Canada},
    publisher = {AAAI Press},
}

@article{DeepBlue,
    author = {Campbell, Murray and Hoane,Jr., A. Joseph and Hsu, Feng-hsiung},
    title = {Deep Blue},
    journal = {Artif. Intell.},
    volume = {134},
    number = {1-2},
    year = {2002},
    issn = {0004-3702},
    pages = {57--83},
    publisher = {Elsevier Science Publishers Ltd.},
    address = {Essex, UK},
}

@article{Gammon,
    author = {Tesauro, Gerald},
    title = {Temporal difference learning and TD-Gammon},
    journal = {Commun. ACM},
    volume = {38},
    number = {3},
    year = {1995},
    issn = {0001-0782},
    pages = {58--68},
    publisher = {ACM},
    address = {New York, NY, USA},
}

@inproceedings{Go,
    author = {Silver, David and Sutton, Richard and M\"{u}ller, Martin},
    title = {Reinforcement learning of local shape in the game of go},
    booktitle = {IJCAI'07: Proceedings of the 20th international joint conference on Artifical intelligence},
    year = {2007},
    pages = {1053--1058},
    location = {Hyderabad, India},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA},
}


@inproceedings{FPS,
    author = {M. McPartland and M. Gallagher},
    title = {Learning to be a Bot: Reinforcement Learning in Shooter Games},
    booktitle = {Proceedings of the fourth Artificial Intelligence in Interactive Digital Entertainment},
    year = {2008},
    location = {Stanford, USA},
}

@mastersthesis{Yavar,
    author = {Yavar Naddaf},
    title = {Game-Independent AI Agents for Playing Atari 2600 Console Games},
    year = {2010},
    school = {University of Alberta},
}

@article{KeepAway,
    author = {Stone, P. and Sutton, R. S. and Kuhlmann, G.},
    title = {Reinforcement learning for robocup soccer keepaway},
    journal = {Adaptive Behavior},
    volume = {13},
    number = {3},
    year = {2005},
    pages = {165--188},
}

@article{Modding,
    author = {El-Nasr, Magy Seif and Smith, Brian K.},
    title = {Learning through game modding},
    journal = {Comput. Entertain.},
    volume = {4},
    number = {1},
    year = {2006},
    issn = {1544-3574},
    pages = {7},
    publisher = {ACM},
    address = {New York, NY, USA},
}



@Book{lamport-1994-ladps,
    author =	{Lamport, Leslie},
    title =	{\LaTeX: A Document Preparation System},
    booktitle =	{\LaTeX: A Document Preparation System},
    year =	1994,
    edition =	2,
    publisher =	{Addison-Wesley},
}

@Book{bringhurst-2002-teots,
    author =	{Bringhurst, Robert},
    title =	{The Elements of Typographic Style},
    booktitle =	{The Elements of Typographic Style},
    year =	2002,
    edition =	{2.5},
    publisher =	{Hartley \& Marks},
}

@InProceedings{kiczales-1997-aop,
    author =    {Kiczales, Gregor and Lamping, John and
        Mendhekar, Anurag and Maeda, Chris and
            Lopes, Cristina and Loingtier, Jean-Marc
            and Irwin, John},
    title =     {Aspect-Oriented Programming},
    booktitle = procecoop,
    year =	1997,
    series =    lncs,
    volume =    2591,
    pages =     {220--242},
    keywords =  {aop, aspect-oriented programming},
    online =	{http://www.parc.xerox.com/csl/groups/sda/pubs/papers/Kiczal
        es-ECOOP97/for-web.pdf},
}

